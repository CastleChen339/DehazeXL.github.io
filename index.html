<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>DemoFusion</title>

    <meta name="description"
        content="Tokenize Image Patches: Global Context Fusion for Effective Haze Removal in Large Images">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- <base href="/"> -->

    <!--     <link rel="apple-touch-icon" href="apple-touch-icon.png"> -->
    <link rel="icon"
        href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ’°</text></svg>">
    <!-- Place favicon.ico in the root directory -->

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="./css/app.css">

    <link rel="stylesheet" href="./css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
    </script>

    <link rel="stylesheet" href="./css/dics.min.css">
    <script src="./js/dics.min.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', domReady);
        function domReady() {
            for (const e of document.querySelectorAll(".b-dics")) {
                new Dics({
                    container: e,
                    textPosition: "top"
                });
            }
        }
    </script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                Tokenize Image Patches: Global Context Fusion for Effective Haze Removal in Large Images</br>
                <img src="https://badges.toozhao.com/badges/01JS93H977KWZMA9C1C90CMR5T/blue.svg" />
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://scholar.google.com/citations?user=w-HpvSsAAAAJ&hl=zh-CN">
                          Jiuchen Chen<sup>1</sup>
                        </a>
                    </li>
                    <li>
                        <a href="https://fengyanzi.github.io/">
                          Xinyu Yan<sup>1</sup>
                        </a>
                    </li>
                    <li>
                        <a href="https://smen.bit.edu.cn/szdw/szml/znjqryjs/qb08/9c74cd529dab4fca8c7d1235e2c6806e.htm">
                          Qizhi Xu<sup>1</sup>
                        </a>
                    </li>
                    <li>
                        <a href="">
                          Kaiqi Li<sup>1</sup>
                        </a>
                    </li>
                </ul>
                <ul class="list-inline">
                    <li>
                        School of Mechatronical Engineering, Beijing Institute of Technology<sup>1</sup>
                    </li>
                </ul>
            </div>
        </div>


        <div class="row">
            <div class="col-md-10 col-md-offset-1 text-center">
                <ul class="nav nav-pills nav-justified">
                    <li>
                        <a href="https://drive.google.com/file/d/1hnr3V_-phWXJr26zQg1s9lay8cG0rXyM/view?usp=sharing">
                                <h4><strong>Paper (4.5MB)</strong></h4>
                        </a>
                    </li>
                    <li>
                        <a href="https://arxiv.org/abs/2504.09621">
                                <h4><strong>Paper (arXiv)</strong></h4>
                        </a>
                    </li>
                    <li>
                        <a href="https://github.com/CastleChen339/DehazeXL">
                                <h4><strong>Code (DehazeXL)</strong></h4>
                        </a>
                    </li>
                    <li>
                        <a href="https://github.com/fengyanzi/DehazingAttributionMap">
                                <h4><strong>Code (DAM)</strong></h4>
                        </a>
                    </li>
                </ul>
            </div>
        </div>
        
    
        <div class="row">
            <div class="col-md-10 col-md-offset-1">
                <h3>
                    <b>Abstract</b>
                </h3>
                <p class="text-justify">
                    Global contextual information and local detail features are essential for haze removal tasks. Deep learning models perform well on small, low-resolution images, but they encounter difficulties with large, high-resolution ones due to GPU memory limitations. As a compromise, they often resort to image slicing or downsampling. The former diminishes global information, while the latter discards high-frequency details. To address these challenges, we propose DehazeXL, a haze removal method that effectively balances global context and local feature extraction, enabling end-to-end modeling of large images on mainstream GPU hardware. Additionally, to evaluate the efficiency of global context utilization in haze removal performance, we design a visual attribution method tailored to the characteristics of haze removal tasks. Finally, recognizing the lack of benchmark datasets for haze removal in large images, we have developed an ultra-high-resolution haze removal dataset (8KDehaze) to support model training and testing. It includes 10000 pairs of clear and hazy remote sensing images, each sized at 8192 Ã— 8192 pixels. Extensive experiments demonstrate that DehazeXL can infer images up to 10240 Ã— 10240 pixels with only 21 GB of memory, achieving state-of-the-art results among all evaluated methods. The source code and experimental dataset are available at https://github.com/CastleChen339/DehazeXL.
                </p>
            </div>
        </div>
      


        <div class="row">
            <div class="col-md-10 col-md-offset-1">
                <h3>
                    <b>DehazeXL</b>
                </h3>
                <br>
                <image src="./figures/framework.png" style="width:100%;" class="img-responsive center-block" alt="overview">
                    <br>
                    <p class="text-justify">
                        Overall architecture of the proposed model. It begins by partitioning the hazy image into uniform-sized patches, which are then encoded into tokens by the Encoder. The Bottleneck injects global information into each token, enhancing the contextual representation. Subsequently, the Decoder reconstructs the tokens back into image patches, forming the final output image. Notably, to minimize memory consumption, both the Encoder and Decoder employ an asynchronous processing strategy, handling the input in multiple mini-batches sequentially rather than simultaneously. This design optimizes memory efficiency while ensuring effective haze removal.
                    </p>
            </div>
        </div>



        <div class="row comp-margin">
            <div class="col-md-10 col-md-offset-1">
                <h3>
                    <b>Results</b>
                </h3>
                    <p class="text-justify">
                        DehazeXL is an end-to-end haze removal method that effectively integrates global information interaction with local details extraction. It is capable of directly inferring large images without incurring quadratic increases in GPU memory usage. DehazeXL demonstrates a reduction in memory usage by approximately 65%-80% when processing large images compared to other methods. Notably, when employing FP16 format for inference, DehazeXL can process 10,240 Ã— 10,240 pixel images with only 21 GB of memory.
                    </p>
            </div>
        </div>




         <div class="row comp-margin">

            <div class="col-md-5 col-md-offset-1">
                <div class="b-dics img-responsive center-block" style="width:100%;">
                    <img src="./figures/cloud_pa_x24_y095_0.jpg" alt="Input" />
                    <img src="./figures/dehaze_pa_x24_y095_0.jpg" alt="DehazeXL" />
                </div>
            </div>

            <div class="col-md-5">
                <div class="b-dics img-responsive center-block" style="width:100%;">
                    <img src="./figures/cloud_10seg550595_0.jpg" alt="Input" />
                    <img src="./figures/dehaze_10seg550595_0.jpg" alt="DehazeXL" />
                </div>
            </div>
            
        </div>


        <div class="row comp-margin">
            <div class="col-md-5 col-md-offset-1">
                <div class="b-dics img-responsive center-block" style="width:100%;">
                    <img src="./figures/cloud_2_2000012.jpg" alt="Input" />
                    <img src="./figures/dehaze_2_2000012.jpg" alt="DehazeXL" />
                </div>
            </div>
            <div class="col-md-5">
                <div class="b-dics img-responsive center-block" style="width:100%;">
                    <img src="./figures/cloud_11_11000019.jpg" alt="Input" />
                    <img src="./figures/dehaze_11_11000019.jpg" alt="DehazeXL" />
                </div>
            </div>
        </div>


        <div class="row comp-margin">
            <div class="col-md-5 col-md-offset-1">
                <div class="b-dics img-responsive center-block" style="width:100%;">
                    <img src="./figures/cloud_k10a7_0.jpg" alt="Input" />
                    <img src="./figures/dehaze_k10a7_0.jpg" alt="DehazeXL" />
                </div>
            </div>
            <div class="col-md-5">
                <div class="b-dics img-responsive center-block" style="width:100%;">
                    <img src="./figures/cloud_k10b12_1.jpg" alt="Input" />
                    <img src="./figures/dehaze_k10b12_1.jpg" alt="DehazeXL" />
                </div>
            </div>
        </div>



        <div class="row">
            <div class="col-md-10 col-md-offset-1">
                <h3>
                    <b>Dehazing Attribution Map</b>
                </h3>
                <br>
                <image src="./figures/lam.png" style="width:100%;" class="img-responsive center-block" alt="overview">
                    <br>
                    <p class="text-justify">
                        To investigate the impact of global information utilization efficiency on dehazing performance, we develop a visual attribution method specifically tailored for haze removal tasks. By analyzing the contribution of each region, we can gain insights into which features are most influential in haze removal, thereby enhancing our understanding of the underlying processes involved. This approach not only facilitates the optimization of model performance but also provides a framework for interpreting results, which is crucial for advancing research in the field.
                    </p>
            </div>
        </div>
        

        <div class="row">
            <div class="col-md-10 col-md-offset-1">
                <h3>
                    <b>Citation</b>
                </h3>
                <p>
                    If you find this paper useful in your research, please consider citing:
                </p>
                <pre>
@inproceedings{chen2025token,
    title={Tokenize Image Patches: Global Context Fusion for Effective Haze Removal in Large Images},
    author={Jiuchen Chen, Xinyu Yan, Qizhi Xu, and Kaiqi Li},
    booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
    year={2025}
    }

@article{chen2025tokenize,
    title={Tokenize Image Patches: Global Context Fusion for Effective Haze Removal in Large Images},
    author={Chen, Jiuchen and Yan, Xinyu and Xu, Qizhi and Li, Kaiqi},
    journal={arXiv preprint arXiv:2504.09621},
    year={2025}
}</pre>
            </div>
        </div>
        
        <div class="row">
            <div class="col-md-10 col-md-offset-1">
                <h3>
                    <b>Acknowledgements</b>
                </h3>
                <p class="text-justify">
                    We would like to thank the authors of <a  href="https://github.com/bair-climate-initiative/xT">bair-climate-initiative/xT</a> for their inspiring work, which has been a valuable reference for our research.
                </p>
            </div>
        </div>

    </div>
</body>

</html>
